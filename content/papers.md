+++
title = "Papers"
+++

Xiao Zhang and David Evans. [_Cost-Sensitive Robustness against Adversarial Examples_](https://arxiv.org/abs/1810.09225). arXiv
prepring, 22 October 2018. [[PDF](https://arxiv.org/pdf/1810.09225.pdf)]

Weilin Xu, David Evans, Yanjun Qi. [_Feature Squeezing: Detecting Adversarial Examples in Deep Neural Networks_](/docs/featuresqueezing.pdf). 
[_2018 Network and Distributed System Security Symposium_](https://www.ndss-symposium.org/ndss2018/). 18-21 February, San Diego, California. Full paper (15 pages): [[PDF](/docs/featuresqueezing.pdf)]

Qixue Xiao, Kang Li, Deyue Zhang, and Weilin Xu. [_Security Risks in Deep Learning Implementations_](https://arxiv.org/abs/1711.11008). <a href="https://www.ieee-security.org/TC/SPW2018/DLS/#"><em>1st Deep Learning and Security Workshop</em></a> (co-located with the 39th <em>IEEE Symposium on Security and Privacy</em>). San Francisco, California. 24 May 2018. [[PDF](https://arxiv.org/pdf/1711.11008.pdf)]

Weilin Xu, David Evans, Yanjun Qi. [_Feature Squeezing Mitigates and Detects
Carlini/Wagner Adversarial Examples_](https://arxiv.org/abs/1705.10686). arXiv preprint, 30 May 2017. [[PDF](https://arxiv.org/pdf/1705.10686.pdf), 3 pages]

Ji Gao, Beilun Wang, Zeming Lin, Weilin Xu, Yanjun Qi. [_DeepCloak: Masking Deep Neural Network Models for Robustness against Adversarial Samples_](https://arxiv.org/abs/1702.06763). ICLR Workshops, 24-26 April 2017. [[PDF](https://arxiv.org/pdf/1702.06763.pdf)]

Weilin Xu, Yanjun Qi, and David Evans. [_Automatically Evading
Classifiers A Case Study on PDF Malware Classifiers_](/docs/evademl.pdf).  [_Network and Distributed Systems Symposium 2016_](https://www.internetsociety.org/events/ndss-symposium-2016), 21-24 February 2016, San Diego, California. Full paper (15 pages): [[PDF](/docs/evademl.pdf)]

